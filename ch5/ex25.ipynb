{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "Some types of data cleaning:\n",
    "- Renaming columns or indexes\n",
    "- Removing irrelevant columns\n",
    "- Splitting or combining columns\n",
    "- Removing non-data, repeated, or rows with missing data\n",
    "- Replacing `NaN` data with values, or interpolating\n",
    "- Standardising strings or fixing typos\n",
    "- Removing whitespace\n",
    "- Correcting datatypes\n",
    "- Identifying and removing/isolating outliers\n",
    "\n",
    "## How much?\n",
    "- `shape[0]` and `count` can be used to determine how many `NaN` values there are, as `shape` includes those values and `count` does not.\n",
    "- `s.isnull().sum()` also provides this when called on a series.\n",
    "- `df.isnull().sum()` tells you how many `NaN` values are in each column\n",
    "- `df.info()` will show some overall summary data, and will show counts if the size is below `pd.options.display.max_info_columns` or if passed `show_counts=True`\n",
    "\n",
    "## pandas vs numpy\n",
    "`isnull()` and `isna()` are the same in pandas, but are *different* from the numpy `np.isnan` method - use the pandas methods.\n",
    "\n",
    "Also pandas uses `~` to do boolean inversion on series and dataframes, which is good to know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,495,734 original and 12,048,375 after dropping NaN values.\n",
      "At $100 a ticket this is $44,735,900 of possibly contested revenue.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../data/nyc-parking-violations-2020.csv\",\n",
    "    usecols=[\n",
    "        \"Plate ID\",\n",
    "        \"Registration State\",\n",
    "        \"Vehicle Make\",\n",
    "        \"Vehicle Color\",\n",
    "        \"Violation Time\",\n",
    "        \"Street Name\",\n",
    "    ],\n",
    ")\n",
    "org_rows = len(df)\n",
    "df = df.dropna()\n",
    "non_nan_rows = len(df)\n",
    "\n",
    "print(f\"{org_rows:,} original and {non_nan_rows:,} after dropping NaN values.\")\n",
    "print(\n",
    "    f\"At $100 a ticket this is ${(org_rows - non_nan_rows) * 100:,} of possibly contested revenue.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,495,734 original and 12,431,949 after dropping NaN values.\n",
      "At $100 a ticket this is $6,378,500 of possibly contested revenue.\n"
     ]
    }
   ],
   "source": [
    "# update this process to only happen if the licence plate, state, car make, or street name are missing\n",
    "df = pd.read_csv(\n",
    "    \"../data/nyc-parking-violations-2020.csv\",\n",
    "    usecols=[\n",
    "        \"Plate ID\",\n",
    "        \"Registration State\",\n",
    "        \"Vehicle Make\",\n",
    "        \"Vehicle Color\",\n",
    "        \"Violation Time\",\n",
    "        \"Street Name\",\n",
    "    ],\n",
    ")\n",
    "org_rows = len(df)\n",
    "df = df[\n",
    "    df[\"Plate ID\"].notnull()\n",
    "    & df[\"Registration State\"].notnull()\n",
    "    & df[\"Vehicle Make\"].notnull()\n",
    "    & df[\"Street Name\"].notnull()\n",
    "]\n",
    "# apparently len(df.index) is a fair bit faster than just len() and also .shape or .size\n",
    "non_nan_rows = len(df.index)\n",
    "\n",
    "print(f\"{org_rows:,} original and {non_nan_rows:,} after dropping NaN values.\")\n",
    "print(\n",
    "    f\"At $100 a ticket this is ${(org_rows - non_nan_rows) * 100:,} of possibly contested revenue.\"\n",
    ")\n",
    "\n",
    "# a nicer way of doing this for the subset is this:\n",
    "# df = df.dropna(subset=[\"Plate ID\", \"Registration State\", \"Vehicle Make\", \"Street Name\"])\n",
    "# this also comes with an additional keyword argument `thresh` which means it'll only happen\n",
    "# if the number of na values is greater than or equal to the threshold value:\n",
    "# df = df.dropna(subset=[\"Plate ID\", \"Registration State\", \"Vehicle Make\", \"Street Name\"], thresh=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,495,734 original and 12,494,116 after dropping NaN values.\n",
      "At $100 a ticket this is $161,800 of possibly contested revenue.\n"
     ]
    }
   ],
   "source": [
    "# only going to drop Plate ID, Registration State, and Street Name invalid values this time\n",
    "df = pd.read_csv(\n",
    "    \"../data/nyc-parking-violations-2020.csv\",\n",
    "    usecols=[\n",
    "        \"Plate ID\",\n",
    "        \"Registration State\",\n",
    "        \"Vehicle Make\",\n",
    "        \"Vehicle Color\",\n",
    "        \"Violation Time\",\n",
    "        \"Street Name\",\n",
    "    ],\n",
    ")\n",
    "org_rows = len(df.index)\n",
    "df = df.dropna(subset=[\"Plate ID\", \"Registration State\", \"Street Name\"])\n",
    "non_nan_rows = len(df.index)\n",
    "\n",
    "print(f\"{org_rows:,} original and {non_nan_rows:,} after dropping NaN values.\")\n",
    "print(\n",
    "    f\"At $100 a ticket this is ${(org_rows - non_nan_rows) * 100:,} of possibly contested revenue.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension questions\n",
    "1. How many rows would be dropped if we wanted at least three of Plate ID, Registration State, Vehicle Make, and Street Name to be invalid?\n",
    "2. Which of the columns you've imported has the greatest number of `NaN` values? Is this a problem?\n",
    "3. Null data is bad, but there is plenty of bad non-null data too. For example many cars with BLANKPLATE were ticketed. Turn these into NaN values and rerun the previous query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../data/nyc-parking-violations-2020.csv\",\n",
    "    usecols=[\n",
    "        \"Plate ID\",\n",
    "        \"Registration State\",\n",
    "        \"Vehicle Make\",\n",
    "        \"Vehicle Color\",\n",
    "        \"Violation Time\",\n",
    "        \"Street Name\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,495,734 original and 12,495,481 after dropping NaN values. Delta of 253\n"
     ]
    }
   ],
   "source": [
    "# 1. drop rows where at least three of the values are NaN\n",
    "org_rows = len(df.index)\n",
    "thresh_df = df.dropna(\n",
    "    subset=[\"Plate ID\", \"Registration State\", \"Vehicle Make\", \"Street Name\"], thresh=3\n",
    ")\n",
    "non_nan_rows = len(thresh_df.index)\n",
    "print(\n",
    "    f\"{org_rows:,} original and {non_nan_rows:,} after dropping NaN values. Delta of {org_rows - non_nan_rows:,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plate ID                 202\n",
       "Registration State         0\n",
       "Vehicle Make           62420\n",
       "Violation Time           278\n",
       "Street Name             1417\n",
       "Vehicle Color         391982\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n",
    "# large number of na values on Vehicle Color isn't really a problem as Plate ID, location and make are\n",
    "# far more important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plate ID                9084\n",
       "Registration State         0\n",
       "Vehicle Make           62420\n",
       "Violation Time           278\n",
       "Street Name             1417\n",
       "Vehicle Color         391982\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Plate ID\"][df[\"Plate ID\"] == \"BLANKPLATE\"] = np.nan\n",
    "df.isna().sum()\n",
    "# close to 9000 blank plates make a bigger dent in revenue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
